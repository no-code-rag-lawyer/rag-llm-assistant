#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
delete_vector.pyï¼ˆDBåŸºæº–ãƒ­ã‚°å¯¾å¿œãƒ»å®‰å®šç‰ˆï¼‰
- DBã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åŸºæº–ã§ã‚´ãƒ¼ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•° / ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’æ­£ç¢ºã«ãƒ­ã‚°å‡ºåŠ›
- å‰Šé™¤å¯¾è±¡ã¯uidå˜ä½ã§å®‰å…¨ã«å®Ÿè¡Œ
"""

import json
from pathlib import Path
from chromadb import PersistentClient
from uid_utils import read_jsonl, write_jsonl_atomic_sync

# === è¨­å®š ===
ROOT = Path("/mydata/llm/vector")
LOG_ROOT = ROOT / "db/log"

CHUNK_LOG = LOG_ROOT / "chunk_log.jsonl"

VECTOR_DB_DIRS = {
    "vector_pdf_word": "/app/db/chroma/pdf_word",
    "vector_excel_calendar": "/app/db/chroma/excel_calendar",
}

VECTOR_UID_LOGS = {
    "vector_pdf_word": LOG_ROOT / "vector_uid_pdf_word.jsonl",
    "vector_excel_calendar": LOG_ROOT / "vector_uid_excel_calendar.jsonl",
}

BATCH_SIZE = 500


def load_chunk_uids() -> set:
    """ãƒãƒ£ãƒ³ã‚¯ãƒ­ã‚°ã‹ã‚‰UIDã‚’å–å¾—"""
    if not CHUNK_LOG.exists():
        print(f"[INFO] ãƒãƒ£ãƒ³ã‚¯ãƒ­ã‚°ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {CHUNK_LOG}")
        return set()
    return {e.get("uid") for e in read_jsonl(CHUNK_LOG) if "uid" in e}


def get_db_ghost_file_map(db_path: str, collection_name: str, valid_uids: set) -> dict:
    """DBãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚´ãƒ¼ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒãƒ£ãƒ³ã‚¯æ•°ã‚’é›†è¨ˆ"""
    ghost_file_map = {}
    client = PersistentClient(path=db_path)
    col = client.get_collection(collection_name)
    metas = col.get(include=["metadatas"]).get("metadatas", [])

    for m in metas:
        uid = m.get("uid")
        if not uid or uid in valid_uids:
            continue
        file_path = m.get("path")
        ghost_file_map.setdefault(file_path, []).append(uid)

    return ghost_file_map


def delete_from_chroma(db_path: str, collection_name: str, ghost_file_map: dict):
    """ä¸è¦ãƒ™ã‚¯ãƒˆãƒ«ã‚’DBã‹ã‚‰å‰Šé™¤ï¼ˆDBãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿åŸºæº–ã®ãƒ•ã‚¡ã‚¤ãƒ«/ãƒãƒ£ãƒ³ã‚¯æ•°ãƒ­ã‚°ä»˜ï¼‰"""
    if not ghost_file_map:
        print(f"[INFO] {collection_name}: ã‚´ãƒ¼ã‚¹ãƒˆãªã—")
        return

    total_files = len(ghost_file_map)
    total_chunks = sum(len(v) for v in ghost_file_map.values())

    print(f"ğŸ—‘ {collection_name}: ã‚´ãƒ¼ã‚¹ãƒˆæ¤œå‡º {total_files} ãƒ•ã‚¡ã‚¤ãƒ« / {total_chunks} ãƒãƒ£ãƒ³ã‚¯ï¼ˆå…ˆé ­10ä»¶è¡¨ç¤ºï¼‰")
    for i, (file_path, uids) in enumerate(ghost_file_map.items()):
        if i >= 10:
            break
        print(f"  - {file_path}ï¼ˆ{len(uids)} ãƒãƒ£ãƒ³ã‚¯ï¼‰")

    # UIDå˜ä½ã§å‰Šé™¤
    all_uids = [uid for uids in ghost_file_map.values() for uid in uids]
    client = PersistentClient(path=db_path)
    col = client.get_collection(collection_name)
    total_deleted = 0
    for i in range(0, len(all_uids), BATCH_SIZE):
        batch = all_uids[i:i + BATCH_SIZE]
        col.delete(where={"uid": {"$in": batch}})
        total_deleted += len(batch)
        print(f"[INFO] ãƒ™ã‚¯ãƒˆãƒ«å‰Šé™¤: {collection_name}ï¼ˆ{total_deleted}/{len(all_uids)} ä»¶å‡¦ç†æ¸ˆï¼‰")

    print(f"[INFO] ãƒ™ã‚¯ãƒˆãƒ«å‰Šé™¤å®Œäº†: {collection_name}ï¼ˆåˆè¨ˆ {total_files} ãƒ•ã‚¡ã‚¤ãƒ« / {total_chunks} ãƒãƒ£ãƒ³ã‚¯ï¼‰")


def save_vector_uid_log(path: Path, db_path: str, collection_name: str):
    """æœ€æ–°ã®DBçŠ¶æ…‹ã‹ã‚‰ãƒ™ã‚¯ã‚¿ãƒ¼ãƒ­ã‚°ã‚’å†ç”Ÿæˆ"""
    client = PersistentClient(path=db_path)
    if collection_name not in [c.name for c in client.list_collections()]:
        write_jsonl_atomic_sync(path, [])
        print(f"[INFO] VectorUIDãƒ­ã‚°ç©ºæ›´æ–°ï¼ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æœªä½œæˆï¼‰: {path.name}")
        return

    col = client.get_collection(collection_name)
    metas = col.get(include=["metadatas"]).get("metadatas", [])
    data = [
        {
            "uid": m.get("uid"),
            "index": m.get("index"),
            "path": m.get("path"),
            "type": m.get("type"),
        }
        for m in metas if m.get("uid")
    ]
    write_jsonl_atomic_sync(path, data)
    print(f"[INFO] VectorUIDãƒ­ã‚°æ›´æ–°: {path.name}ï¼ˆ{len(data)} ä»¶ï¼‰")


def main():
    print("â–¶ï¸ delete_vector.py é–‹å§‹ï¼ˆDBåŸºæº–ãƒ­ã‚°å¯¾å¿œãƒ»å®‰å®šç‰ˆï¼‰")

    valid_uids = load_chunk_uids()
    print(f"[INFO] æœ‰åŠ¹ãƒãƒ£ãƒ³ã‚¯UIDæ•°: {len(valid_uids)}")

    for key, db_path in VECTOR_DB_DIRS.items():
        print(f"=== {key} å‡¦ç†é–‹å§‹ ===")
        client = PersistentClient(path=db_path)
        collections = [c.name for c in client.list_collections()]
        if key not in collections:
            print(f"[INFO] {key}: ç™»éŒ²æ¸ˆã¿ãƒ™ã‚¯ãƒˆãƒ«ãªã—ï¼ˆã‚¹ã‚­ãƒƒãƒ—ï¼‰")
            save_vector_uid_log(VECTOR_UID_LOGS[key], db_path, key)
            continue

        ghost_file_map = get_db_ghost_file_map(db_path, key, valid_uids)
        delete_from_chroma(db_path, key, ghost_file_map)
        save_vector_uid_log(VECTOR_UID_LOGS[key], db_path, key)

    print("âœ… delete_vector.py å®Œäº†")


if __name__ == "__main__":
    main()



























